# Summary 
## (i) Reference : Jane Cleland-Huang, Raffaella Settimi, Chuan Duan and Xuchang Zou @ IC Req Engg 2005. Utilizing supporting evidence to improve dynamic requirements traceability. [Paper](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1531035&tag=1)

## (ii) Keywords

  * (ii1)**Requirements Tracability** : It defines the ability to track down the life of a requirement back to its source documents. The source documents can range from databases, spreadsheets, flat files etc.
  * (ii2)**Information Search** : Information search refers to retrieving relevant information using various sources. Its a part of consumer decision process where a consumer looks for internal or external information(wiki).
  * (ii3)**Clustering** : clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). (wiki)
  * (ii4)**Graph Pruning**  : Pruning is a technique in machine learning that reduces the size of tree/graph by removing sections of the tree/graph that provide little information to describe it. 

## (iii) Artifacts
  * (iii1) **Motivation** :  Dynamic retrieval methods minimize the need for creating and maintianing explicit links and can significatntly reduce the effort required to perform a manual trace. These methods have recall and precision problems. Typical industrial practices in which traceability matrices are manually constructed and maintained tend to be costly to implement and are financially non-viable. Current research has investigated the use of dynamic retrieval methods to automate the process of generating traceability links. These approaches are based on information retrieval methods that link artifacts according to the occurrence of terms in both the requirement and set of searchable documents or on the grammatical structuring of the terms. Results from these approaches are promising because they clearly demonstrate the feasibility of replacing traditional trace methods with dynamic ones, but unfortunately they also suffer from precision problems.
  * (iii2) **Hypotheses** : The proposed method uses manually created tracability matricies to train a trace classifier, while another method uses web mining techniques to reconstruct the original trace query.Machine learning methods are particularly appealing for tracing regulatory codes, because the upfront effort of training a classifier can be potentially recouped when those same codes are applied across future projects. When a training set is not available, web mining approach can be used to retrieve relavant set of indicator terms from the internet. This method augments the predictions by machine learning approach. In hierarchical enhancement ancestors that are closer to the query q are likely to provide stronger information about the query, compared to other ancestors that lay farther away in the query hierarchy. Clustering enhancements are based on the premise that links tend to occur in clusters. If a link exists between a query and a document, and if that document is part of a logical cluster of documents, then there would be a higher probability that additional links should exist between the same query and other documents in that cluster. 
  * (iii3) **Sampling Procedures** : The Ice Breaker System (IBS) was initially described in and enhanced with requirements mined from documents obtained from the public work departments of Charlotte, Colorado; Greeley, Colorado; and the Region of Peel, Ontario.  The Ice Breaker system consists of 180 functional requirements, 72 classes, and 18 packages. The Event-Based Traceability (EBT) system, which was initially developed at the International Center for Software Engineering at the University of Illinois at Chicago, provides a dynamic traceability infrastructure based on the publish-subscribe scheme for maintaining artifacts during long-term change maintenance. It is composed of 54 requirements, 60 classes, and 8 packages. Artifacts in the third data set were reconstructed from the well documented Light Control system (LC) developed for the University of Kaiserslautern. This system controls the lights in a building based upon user defined lighting schemes, building occupation, and current exterior illumination. Our version of this system consisted of 36 requirements, 25 classes, and 5 packages. For each of these data sets UML diagrams were developed in Poseidon, exported to XMI and then parsed into the Poirot:Tracemaker tool. Requirements were entered directly into Poirot’s database. For analysis purposes, a traceability matrix was constructed that identified the true-links that the retrieval algorithm should attempt to retrieve. This matrix was used to evaluate the performance of each of the enhancement strategies in terms of recall and precision metrics.
  * (iii4) **Patterns and Anti Patterns** :
   * **_Patterns_** : 
    *  Trace retrieval strategies must favor recall over precision, where recall measures the number of correctly retrieved documents out of the entire set of correct documents, and precision measures the number of correctly retrieved documents out of the set of retrieved documents.
    *  Words that appear in fewer documents are considered to be more informative in defining the relevance of a document to the query.
    *  The threshold values were selected by optimizing the objective function “maximize Recall + Precision, where Recall > T%”, where T% is a target recall chosen by the user. This is equivalent to finding the threshold value which maximizes both recall and precision while maintaining a sufficiently high recall level to effectively support requirements traceability.
    *  In the trace retrieval problem the threshold is deliberately set low so that a high percentage of true-links will be recalled. Pairs of artifacts whose relevance scores appear below the threshold value can be safely assumed, with high degree of confidence, to be non-links.
    *  Low confidence links were retrieved only if the average probability between the query and document’s cluster was greater than enhanced threshold. The algorithm is depicted below and can be applied to query side clustering by reversing the document and query terms in the algorithm. 
   * **_Anti Patterns_** :
    * If a query returns 70% of the critical links but fails to find the remaining 30%, then the query could be ineffective in supporting impact analysis, and a critical side effect of a proposed change could go unnoticed.
    * The basic retrieval algorithm retrieves both of these links at similar probability values and is unable to filter out the incorrect link.

## (iv) Improvisations:
  * (iv1) Keywords for the paper could have been highlighted
  * (iv2) The repository for the data used could have been provided to repeat the experiments.
  * (iv3) Psuedocode or link to the codebase would have helped get a better picture of the approach
